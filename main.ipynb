{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import librosa\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "import os\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocess import *"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "spec,y,sr = audio_to_spectrogram('kangaroo.wav',duration=10)\n",
    "s2a = spectrogram_to_audio(y)\n",
    "save_audio_as_wav(s2a)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def GramMatrix(input):\n",
    "    # A = batch\n",
    "    # B = Number of feature maps\n",
    "    # C,D = Dimension of feature maps\n",
    "    a,b,c,d = input.size()\n",
    "\n",
    "    features = input.view(a*b,c*d)\n",
    "\n",
    "    G = torch.mm(features, features.t())\n",
    "\n",
    "    #Normalize by dividing by total\n",
    "    return G.div(a*b*c*d)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self,latent_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1,32,kernel_size=3,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64,kernel_size=3,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,128,kernel_size=3,stride=2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_mu = nn.Linear(128 * 16 * 16, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(128 * 16 * 16, latent_dim)\n",
    "        \n",
    "        self.decoder_fc = nn.Linear(latent_dim, 128 * 16 * 16)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128,64,kernel_size=3,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64,32,kernel_size=3,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32,16,kernel_size=3,stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16,8,kernel_size=3,stride=2),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    \n",
    "    def encode(self,x):\n",
    "        x = self.encoder(x)\n",
    "        mean, logvar = self.fc_mu(x), self.fc_logvar(x)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        eps = torch.randn_like(mu).to(device)\n",
    "        z = mu + logvar * eps\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mean, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mean, logvar"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def loss_fn(recon,original,mu,logvar):\n",
    "    recon_loss = F.mse_loss(recon,original,reduction='sum')\n",
    "    kl_div = -0.5 * torch.sum(1+ logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss,kl_div"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = VAE(latent_dim=64).to(device)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "optimizer = optim.Adam(model.parameters(), lr=1e-3)",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
